{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf \n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 8s 1us/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimage_index = 50555 # You may select anything up to 60,000\nprint(y_train[image_index]) # The label is 8\nplt.imshow(x_train[image_index], cmap='Greys')\n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "8\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7f355c0e95f8>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train.shape\n",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "(60000, 28, 28)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\ninput_shape = (28, 28, 1)\n# Making sure that the values are float so that we can get decimal points after division\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n# Normalizing the RGB codes by dividing it to the max RGB value.\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint('Number of images in x_train', x_train.shape[0])\nprint('Number of images in x_test', x_test.shape[0])",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "x_train shape: (60000, 28, 28, 1)\nNumber of images in x_train 60000\nNumber of images in x_test 10000\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Importing the required Keras modules containing model and layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n# Creating a Sequential Model and adding the layers\nmodel = Sequential()\nmodel.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten()) # Flattening the 2D arrays for fully connected layers\nmodel.add(Dense(128,activation=tf.nn.relu))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation=tf.nn.softmax))",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.fit(x=x_train,y=y_train, epochs=10)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n60000/60000 [==============================] - 183s 3ms/step - loss: 0.2088 - accuracy: 0.9367\nEpoch 2/10\n60000/60000 [==============================] - 180s 3ms/step - loss: 0.0830 - accuracy: 0.97470s - loss: 0.0830 - accuracy: 0.\nEpoch 3/10\n60000/60000 [==============================] - 182s 3ms/step - loss: 0.0571 - accuracy: 0.98170s - loss: 0.0572 - ac\nEpoch 4/10\n60000/60000 [==============================] - 180s 3ms/step - loss: 0.0436 - accuracy: 0.9857\nEpoch 5/10\n60000/60000 [==============================] - 186s 3ms/step - loss: 0.0332 - accuracy: 0.9894\nEpoch 6/10\n60000/60000 [==============================] - 166s 3ms/step - loss: 0.0306 - accuracy: 0.9897\nEpoch 7/10\n60000/60000 [==============================] - 161s 3ms/step - loss: 0.0250 - accuracy: 0.9919\nEpoch 8/10\n60000/60000 [==============================] - 170s 3ms/step - loss: 0.0211 - accuracy: 0.9929\nEpoch 9/10\n60000/60000 [==============================] - 163s 3ms/step - loss: 0.0193 - accuracy: 0.9933\nEpoch 10/10\n60000/60000 [==============================] - 174s 3ms/step - loss: 0.0193 - accuracy: 0.9937\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<keras.callbacks.callbacks.History at 0x7f3559461c88>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.evaluate(x_test, y_test)\n",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "10000/10000 [==============================] - 11s 1ms/step\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "[0.06232951707619227, 0.9847000241279602]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Comparisions between activation functions:\n---------------------------------------------------------------\nSigmoid - 0.04310258559571812, 0.9861999750137329\nRelu    - 0.06232951707619227, 0.9847000241279602\n\n\nfashion_mnist\n\nRelu    - 0.296536854416132, 0.9118000268936157\nsigmoid - 0.2550588166356087, 0.9125999808311462\n\n\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}